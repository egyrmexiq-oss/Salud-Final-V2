import streamlit as st
import google.generativeai as genai

# --- CONFIGURACI√ìN DE P√ÅGINA ---
st.set_page_config(page_title="HealthExpert AI", page_icon="ü©∫", layout="centered")

# --- CONEXI√ìN SEGURA ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
except Exception:
    st.error("‚ö†Ô∏è Error: No se encontr√≥ la API KEY en los Secrets.")
    st.stop()

# --- CEREBRO: SYSTEM PROMPT ---
SYSTEM_PROMPT = """
Eres un Asistente Experto en Contexto de Salud.
REGLA DE ORO: En TODAS tus respuestas incluye al final: "‚ö†Ô∏è IMPORTANTE: No soy un profesional de la salud. Informaci√≥n educativa. Acuda a un m√©dico."

Tu tono y profundidad dependen del nivel seleccionado:
- Nivel B√°sica: Explicaci√≥n sencilla, analog√≠as, para p√∫blico general.
- Nivel Media: Lenguaje formal, cita fuentes generales.
- Nivel Experto: Terminolog√≠a m√©dica, patolog√≠as, protocolos, NOMs y efectos secundarios.

Si el usuario pregunta algo ajeno a salud, responde amablemente que solo puedes hablar de temas m√©dicos.
"""

# --- GESTI√ìN DE MEMORIA ---
if "nivel" not in st.session_state:
    st.session_state.nivel = None
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []

# Funci√≥n para resetear
def nueva_consulta():
    st.session_state.nivel = None
    st.session_state.mensajes = []
    st.rerun()

# --- INTERFAZ ---
st.title("ü©∫ HealthExpert AI")

# ESCENA 1: SELECCI√ìN DE NIVEL
if st.session_state.nivel is None:
    st.markdown("### Bienvenido. Selecciona el nivel de profundidad para tu consulta:")
    
    col1, col2, col3 = st.columns(3)
    if col1.button("üü¢ B√ÅSICO\n(Sencillo)", use_container_width=True):
        st.session_state.nivel = "B√°sica"
        st.rerun()
    if col2.button("üü° MEDIO\n(Detallado)", use_container_width=True):
        st.session_state.nivel = "Media"
        st.rerun()
    if col3.button("üî¥ EXPERTO\n(T√©cnico)", use_container_width=True):
        st.session_state.nivel = "Experto"
        st.rerun()

# ESCENA 2: CHAT ACTIVO
else:
    # Barra superior con estado y bot√≥n de salir
    c1, c2 = st.columns([3, 1])
    with c1:
        st.info(f"Modo Activo: **Nivel {st.session_state.nivel}**")
    with c2:
        if st.button("üîÑ Nueva Consulta"):
            nueva_consulta()

    # Mostrar historial
    for m in st.session_state.mensajes:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # Caja de entrada
    prompt = st.chat_input("Escribe tu consulta m√©dica aqu√≠...")
    
    if prompt:
        # 1. Mostrar mensaje usuario
        st.chat_message("user").markdown(prompt)
        st.session_state.mensajes.append({"role": "user", "content": prompt})

        try:
            # 2. Preparar el "S√°ndwich" de contexto para la IA
            prompt_completo = f"""
            {SYSTEM_PROMPT}
            ----------------
            CONTEXTO: El usuario eligi√≥ NIVEL {st.session_state.nivel}.
            Pregunta del usuario: "{prompt}"
            """
            
            # 3. LLAMADA AL MODELO (Usamos el que encontramos en tu lista)
            model = genai.GenerativeModel('gemini-2.5-flash')
            
            with st.spinner("Analizando consulta..."):
                response = model.generate_content(prompt_completo)
                respuesta_ia = response.text

            # 4. Mostrar respuesta IA
            with st.chat_message("assistant"):
                st.markdown(respuesta_ia)
            st.session_state.mensajes.append({"role": "assistant", "content": respuesta_ia})
            
        except Exception as e:
            st.error(f"Error de conexi√≥n: {e}")
