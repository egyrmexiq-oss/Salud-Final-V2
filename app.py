import streamlit as st
import google.generativeai as genai

# --- VERIFICACI√ìN DE VERSI√ìN ---
st.set_page_config(page_title="HealthExpert AI", page_icon="ü©∫")
st.title("‚úÖ VERSI√ìN FINAL - CONECTADA")

# --- API KEY ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
except Exception:
    st.error("‚ö†Ô∏è Faltan los Secretos. Configura la GEMINI_API_KEY en Streamlit.")
    st.stop()

# --- SYSTEM PROMPT ---
SYSTEM_PROMPT = """
Eres un Asistente Experto en Contexto de Salud.
REGLA: Si el usuario eligi√≥ un nivel, responde ESTRICTAMENTE en ese nivel.
- Nivel B√°sico: Explicaci√≥n sencilla, como a un ni√±o de 12 a√±os.
- Nivel Medio: Explicaci√≥n formal, citando fuentes generales.
- Nivel Experto: Terminolog√≠a m√©dica, patolog√≠as, protocolos y NOMs.
"""

# --- INICIALIZAR ESTADO ---
if "nivel" not in st.session_state:
    st.session_state.nivel = None
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []

# --- PANTALLA 1: SELECCI√ìN DE NIVEL ---
if st.session_state.nivel is None:
    st.info("üëã Hola. Para empezar, selecciona tu nivel de profundidad:")
    c1, c2, c3 = st.columns(3)
    if c1.button("B√ÅSICO (Sencillo)"):
        st.session_state.nivel = "B√°sica"
        st.rerun()
    if c2.button("MEDIO (Detallado)"):
        st.session_state.nivel = "Media"
        st.rerun()
    if c3.button("EXPERTO (T√©cnico)"):
        st.session_state.nivel = "Experto"
        st.rerun()

# --- PANTALLA 2: CHAT ---
else:
    st.success(f"Modo Activo: {st.session_state.nivel}")
    if st.button("Cambiar Nivel"):
        st.session_state.nivel = None
        st.session_state.mensajes = []
        st.rerun()

    # Historial
    for m in st.session_state.mensajes:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # Input
    prompt = st.chat_input("Escribe tu consulta m√©dica...")
    
    if prompt:
        st.chat_message("user").markdown(prompt)
        st.session_state.mensajes.append({"role": "user", "content": prompt})

        try:
            # L√≥gica del Prompt Oculto
            full_prompt = f"""
            {SYSTEM_PROMPT}
            CONTEXTO: El usuario eligi√≥ NIVEL {st.session_state.nivel}.
            Pregunta del usuario: {prompt}
            """
            
            # Usamos el modelo Flash
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(full_prompt)
            
            text = response.text
            with st.chat_message("assistant"):
                st.markdown(text)
            st.session_state.mensajes.append({"role": "assistant", "content": text})
            
        except Exception as e:
            st.error(f"Error de conexi√≥n: {e}")
